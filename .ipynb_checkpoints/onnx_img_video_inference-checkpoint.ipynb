{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageColor\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import pathlib\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "CWD_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "model = 'model.onnx'\n",
    "input_img_path = 'input_image_path'\n",
    "output_img_path = 'output_image_path'\n",
    "print(rt.get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = pathlib.Path(input_img_path)\n",
    "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
    "TEST_IMAGE_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(model)\n",
    "\n",
    "def sess_run(img_data, sess):\n",
    "    s = time.time()\n",
    "    #sess = rt.InferenceSession(model)\n",
    "    # we want the outputs in this order\n",
    "    outputs = [\"num_detections\", \"detection_boxes\", \"detection_scores\", \"detection_classes\"]\n",
    "    result = sess.run(outputs, {\"input_tensor\": img_data})\n",
    "    num_detections, detection_boxes, detection_scores, detection_classes = result\n",
    "    detection_time = time.time() - s\n",
    "    print('detection_time : ', detection_time)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "            1: 'class_1',\n",
    "            2: 'class_2',\n",
    "            3: 'class_3',\n",
    "            4: 'class_4',\n",
    "            5: 'class_5',\n",
    "            6: 'class_6',\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detection(draw, d, c, s, img):\n",
    "    \"\"\"Draw box and label for 1 detection.\"\"\"\n",
    "    width, height = draw.im.size\n",
    "    # the box is relative to the image size so we multiply with height and width to get pixels.\n",
    "    top = d[0] * height\n",
    "    left = d[1] * width\n",
    "    bottom = d[2] * height\n",
    "    right = d[3] * width\n",
    "    top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "    left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "    bottom = min(height, np.floor(bottom + 0.5).astype('int32'))\n",
    "    right = min(width, np.floor(right + 0.5).astype('int32'))\n",
    "    label = stop_and_speed_limit_classes[c]\n",
    "    s = str(s)\n",
    "    label = label+\" : \"+s\n",
    "    print('objects : ', label)\n",
    "    label_size = draw.textsize(label)\n",
    "    if top - label_size[1] >= 0:\n",
    "        text_origin = tuple(np.array([left, top - label_size[1]]))\n",
    "    else:\n",
    "        text_origin = tuple(np.array([left, top + 1]))\n",
    "    color = ImageColor.getrgb(\"green\")\n",
    "    thickness = 1\n",
    "    draw.rectangle([left + thickness, top + thickness, right - thickness, bottom - thickness], outline=color)\n",
    "    draw.text(text_origin, label, fill=color)  # , font=font)\n",
    "    img = np.array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inference_image(image_path, model):\n",
    "    print(image_path)\n",
    "    head_tail = os.path.split(image_path)\n",
    "    tail = head_tail[1]\n",
    "    start_time = time.time()\n",
    "    img = Image.open(image_path)\n",
    "    img_data = np.array(img)\n",
    "    img_data = np.expand_dims(img_data.astype(np.uint8), axis=0)\n",
    "    result = sess_run(img_data, model)\n",
    "    num_detections = result[0]\n",
    "    detection_boxes = result[1]\n",
    "    detection_scores = result[2]\n",
    "    detection_classes = result[3]\n",
    "    batch_size = num_detections.shape[0]\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for batch in range(0, batch_size):\n",
    "        for detection in range(0, int(num_detections[batch])):\n",
    "            if detection_scores[0][detection] > 0.5:\n",
    "\n",
    "                c = detection_classes[batch][detection]\n",
    "                d = detection_boxes[batch][detection]\n",
    "                s = detection_scores[0][detection]\n",
    "                s = round(s,4)\n",
    "                out = draw_detection(draw, d, c, s, img)\n",
    "                return out\n",
    "                out.save(os.path.join(CWD_PATH, output_img_path,tail))\n",
    "    end_time = time.time() - start_time\n",
    "    print('onnx_inference_time : ',end_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inference(image_path, model,frame_number):\n",
    "    #print(image_path)\n",
    "    start_time = time.time()\n",
    "    img = Image.fromarray(image_path)\n",
    "    img_data = image_path\n",
    "    img_data = np.expand_dims(img_data.astype(np.uint8), axis=0)\n",
    "    result = sess_run(img_data, model)\n",
    "    num_detections = result[0]\n",
    "    detection_boxes = result[1]\n",
    "    detection_scores = result[2]\n",
    "    detection_classes = result[3]\n",
    "    batch_size = num_detections.shape[0]\n",
    "    #print(batch_size)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    #print(draw)\n",
    "    for batch in range(0, batch_size):\n",
    "        for detection in range(0, int(num_detections[batch])):\n",
    "            if detection_scores[0][detection] > 0.5:\n",
    "                print('---detected_sign_frame---',frame_number)\n",
    "                c = detection_classes[batch][detection]\n",
    "                d = detection_boxes[batch][detection]\n",
    "                s = detection_scores[0][detection]\n",
    "                s = round(s,4)\n",
    "                out = draw_detection(draw, d, c, s, img)\n",
    "                return out\n",
    "                #print(detection)\n",
    "    end_time = time.time() - start_time\n",
    "    print('onnx_inference_time : ',end_time )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = 'test_videos'\n",
    "PATH_TO_TEST_VIDEO_DIR = pathlib.Path(input_video_path)\n",
    "TEST_VIDEO_PATHS = sorted(list(PATH_TO_TEST_VIDEO_DIR.glob(\"*.mp4\")))\n",
    "TEST_VIDEO_PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for video_path in TEST_VIDEO_PATHS:\n",
    "    video_path = str(video_path)\n",
    "    head_tail = os.path.split(video_path)\n",
    "    tail = head_tail[1]\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    #output_path = os.path.join(output_dir, 'detection_'+ Video_path.split(\"/\")[-1])\n",
    "    output_path = 'output_videos_onnx/output_'+tail\n",
    "    print('output_path :', output_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*\"mp4v\"), 30, (frame_width, frame_height))\n",
    "    property_id = int(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    total_number_of_frames = int(cv2.VideoCapture.get(cap, property_id))\n",
    "    print('--total_number_of_frames-- ', total_number_of_frames)\n",
    "    while (cap.isOpened()):\n",
    "        ret, img = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        #timestamp1 = time.time()\n",
    "        #det_boxes = detector.DetectFromImage(img)\n",
    "        #elapsed_time = round((time.time() - timestamp1) * 1000) #ms\n",
    "        frame_number = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        print('--frame_number--',frame_number)\n",
    "        img = save_inference(img, sess, frame_number)\n",
    "        out.write(img)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()   \n",
    "    end = time.time() - start\n",
    "print('total_time : ', end, 'sec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
